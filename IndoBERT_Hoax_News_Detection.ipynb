{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IndoBERT Hoax News Detection",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLrHTVMSTxbt"
      },
      "source": [
        "# IndoBERT for Bahasa Indonesia Hoax News Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LATDuyAVYEsw"
      },
      "source": [
        "### Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBr2V8S1LAt1"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np \r\n",
        "import torch\r\n",
        "\r\n",
        "!pip install transformers\r\n",
        "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Preliminaries\r\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\r\n",
        "\r\n",
        "# Models\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "# Training\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "# Evaluation\r\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\r\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfNKumAzxkFn"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Drive\r\n",
        "from google.colab import files\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpgSBoLxtDt2"
      },
      "source": [
        "source_folder = '/content/drive/My Drive/transformers/Data'\r\n",
        "destination_folder = '/content/drive/My Drive/transformers/Model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYRz41w8x28A"
      },
      "source": [
        "%cd /content/drive/My Drive/transformers/Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D87UOuPvZWf9"
      },
      "source": [
        "## Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtWXlthhPvxl"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWg-WDVbWyGO"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7sIHRLwaoyM"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeZ14Ky5Lqih"
      },
      "source": [
        "# Model parameter\r\n",
        "MAX_SEQ_LEN = 128\r\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\r\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\r\n",
        "\r\n",
        "# Fields\r\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.int64)\r\n",
        "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True,\r\n",
        "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\r\n",
        "fields = [('tanggal', text_field),('judul', text_field),('narasi', text_field),('label', label_field)]\r\n",
        "\r\n",
        "train,valid,test = TabularDataset.splits(path=source_folder, train='train.csv', validation='valid.csv', test='test.csv', \r\n",
        "                                           format='csv', fields=fields, skip_header=True)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSKPey98jRpM"
      },
      "source": [
        "# Iterators\r\n",
        "train_iter = BucketIterator(train, batch_size=8, sort_key=lambda x: len(x.narasi),\r\n",
        "                            device=device, train=True, sort=True, sort_within_batch=True)\r\n",
        "valid_iter = BucketIterator(valid, batch_size=8, sort_key=lambda x: len(x.narasi),\r\n",
        "                            device=device, train=True, sort=True, sort_within_batch=True)\r\n",
        "test_iter = Iterator(test, batch_size=8, device=device, train=False, shuffle=False, sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfFxkaJq1WmC"
      },
      "source": [
        "class BERT(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(BERT, self).__init__()\r\n",
        "\r\n",
        "        options_name = \"indobenchmark/indobert-base-p1\"\r\n",
        "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\r\n",
        "\r\n",
        "    def forward(self, text, label):\r\n",
        "        loss, text_fea = self.encoder(text, labels=label)[:2]\r\n",
        "\r\n",
        "        return loss, text_fea"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egjaxiu51prx"
      },
      "source": [
        "# Save and Load Functions\r\n",
        "\r\n",
        "def save_checkpoint(save_path, model, valid_loss):\r\n",
        "\r\n",
        "    if save_path == None:\r\n",
        "        return\r\n",
        "    \r\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\r\n",
        "                  'valid_loss': valid_loss}\r\n",
        "    \r\n",
        "    torch.save(state_dict, save_path)\r\n",
        "    print(f'Model saved to ==> {save_path}')\r\n",
        "\r\n",
        "def load_checkpoint(load_path, model):\r\n",
        "    \r\n",
        "    if load_path==None:\r\n",
        "        return\r\n",
        "    \r\n",
        "    state_dict = torch.load(load_path, map_location=device)\r\n",
        "    print(f'Model loaded from <== {load_path}')\r\n",
        "    \r\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\r\n",
        "    return state_dict['valid_loss']\r\n",
        "\r\n",
        "\r\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\r\n",
        "\r\n",
        "    if save_path == None:\r\n",
        "        return\r\n",
        "    \r\n",
        "    state_dict = {'train_loss_list': train_loss_list,\r\n",
        "                  'valid_loss_list': valid_loss_list,\r\n",
        "                  'global_steps_list': global_steps_list}\r\n",
        "    \r\n",
        "    torch.save(state_dict, save_path)\r\n",
        "    print(f'Model saved to ==> {save_path}')\r\n",
        "\r\n",
        "\r\n",
        "def load_metrics(load_path):\r\n",
        "\r\n",
        "    if load_path==None:\r\n",
        "        return\r\n",
        "    \r\n",
        "    state_dict = torch.load(load_path, map_location=device)\r\n",
        "    print(f'Model loaded from <== {load_path}')\r\n",
        "    \r\n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsAT0DKHZ1si"
      },
      "source": [
        "## Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWwCKZ2z12Nr"
      },
      "source": [
        "# Training Function\r\n",
        "\r\n",
        "def train(model,\r\n",
        "          optimizer,\r\n",
        "          criterion = nn.BCELoss(),\r\n",
        "          train_loader = train_iter,\r\n",
        "          valid_loader = valid_iter,\r\n",
        "          num_epochs = 8,\r\n",
        "          eval_every = len(train_iter) // 2,\r\n",
        "          file_path = destination_folder,\r\n",
        "          best_valid_loss = float(\"Inf\")):\r\n",
        "    \r\n",
        "    # initialize running values\r\n",
        "    running_loss = 0.0\r\n",
        "    valid_running_loss = 0.0\r\n",
        "    global_step = 0\r\n",
        "    train_loss_list = []\r\n",
        "    valid_loss_list = []\r\n",
        "    global_steps_list = []\r\n",
        "\r\n",
        "    # training loop\r\n",
        "    model.train()\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "        for (date, title, text, labels), _ in train_loader:\r\n",
        "            labels = labels.type(torch.LongTensor)           \r\n",
        "            labels = labels.to(device)\r\n",
        "            text = text.type(torch.LongTensor)  \r\n",
        "            text = text.to(device)\r\n",
        "            output = model(text, labels)\r\n",
        "            loss, _ = output\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            # update running values\r\n",
        "            running_loss += loss.item()\r\n",
        "            global_step += 1\r\n",
        "\r\n",
        "            # evaluation step\r\n",
        "            if global_step % eval_every == 0:\r\n",
        "                model.eval()\r\n",
        "                with torch.no_grad():                    \r\n",
        "\r\n",
        "                    # validation loop\r\n",
        "                    for (date, title, text, labels), _ in valid_loader:\r\n",
        "                        labels = labels.type(torch.LongTensor)           \r\n",
        "                        labels = labels.to(device)\r\n",
        "                        text = text.type(torch.LongTensor)  \r\n",
        "                        text = text.to(device)\r\n",
        "                        output = model(text, labels)\r\n",
        "                        loss, _ = output\r\n",
        "                        \r\n",
        "                        valid_running_loss += loss.item()\r\n",
        "\r\n",
        "                # evaluation\r\n",
        "                average_train_loss = running_loss / eval_every\r\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\r\n",
        "                train_loss_list.append(average_train_loss)\r\n",
        "                valid_loss_list.append(average_valid_loss)\r\n",
        "                global_steps_list.append(global_step)\r\n",
        "\r\n",
        "                # resetting running values\r\n",
        "                running_loss = 0.0                \r\n",
        "                valid_running_loss = 0.0\r\n",
        "                model.train()\r\n",
        "\r\n",
        "                # print progress\r\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\r\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\r\n",
        "                              average_train_loss, average_valid_loss))\r\n",
        "                \r\n",
        "                # checkpoint\r\n",
        "                if best_valid_loss > average_valid_loss:\r\n",
        "                    best_valid_loss = average_valid_loss\r\n",
        "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\r\n",
        "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\r\n",
        "    \r\n",
        "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\r\n",
        "    print('Finished Training!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgEMeGkE25GR"
      },
      "source": [
        "model = BERT().to(device)\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-5)\r\n",
        "\r\n",
        "train(model=model, optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB-0Up2JSsCC"
      },
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\r\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\r\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\r\n",
        "plt.xlabel('Global Steps')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HlW7cvQaYvl"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcQfFEFS1AB"
      },
      "source": [
        "# Evaluation Function\r\n",
        "\r\n",
        "def evaluate(model, test_loader):\r\n",
        "    y_pred = []\r\n",
        "    y_true = []\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        for (date, title, text, labels), _ in test_loader:\r\n",
        "\r\n",
        "                labels = labels.type(torch.LongTensor)           \r\n",
        "                labels = labels.to(device)\r\n",
        "                text = text.type(torch.LongTensor)  \r\n",
        "                text = text.to(device)\r\n",
        "                output = model(text, labels)\r\n",
        "\r\n",
        "                _, output = output\r\n",
        "                y_pred.extend(torch.argmax(output, 1).tolist())\r\n",
        "                y_true.extend(labels.tolist())\r\n",
        "    \r\n",
        "    print('Classification Report:')\r\n",
        "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\r\n",
        "    \r\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\r\n",
        "    ax= plt.subplot()\r\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\r\n",
        "\r\n",
        "    ax.set_title('Confusion Matrix')\r\n",
        "\r\n",
        "    ax.set_xlabel('Predicted Labels')\r\n",
        "    ax.set_ylabel('True Labels')\r\n",
        "\r\n",
        "    ax.xaxis.set_ticklabels(['HOAX', 'REAL'])\r\n",
        "    ax.yaxis.set_ticklabels(['HOAX', 'REAL'])\r\n",
        "\r\n",
        "best_model = BERT().to(device)\r\n",
        "\r\n",
        "load_checkpoint(destination_folder + '/model.pt', best_model)\r\n",
        "\r\n",
        "evaluate(best_model, test_iter)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}